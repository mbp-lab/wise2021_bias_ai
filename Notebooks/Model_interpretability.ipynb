{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37f10814",
   "metadata": {},
   "source": [
    "<table style=\"width:100%; border:0\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\" align=\"left|left|right\">\n",
    "  <tr style=\"border:0\">\n",
    "  <td style=\"border: 0; font-size:60px\" rowspan=\"3\"><b>Universit√§t Bielefeld</b></td>\n",
    "    <td style=\"border: 0\">CITEC / Faculty of Technology</td>\n",
    "  </tr>\n",
    "  <tr style=\"border:0\">\n",
    "    <td style=\"border: 0\">Multimodal Behavior Processing Group</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c431a99c",
   "metadata": {},
   "source": [
    "# Model Interpretability\n",
    "In this notebook you will use some model interpretability methods for exploring the predictions of the Adult dataset with [Lime](https://github.com/marcotcr/lime) and the [CelebA](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) image dataset using the [innvestigate](https://github.com/albermax/innvestigate) library.\n",
    "\n",
    "__NOTE__: Before getting started make sure you have followed the instructions in the `Model_interpretability_README.md` and validated your conda installation with `Model_interpretability_Lib_validation.ipynb`\n",
    "\n",
    "\n",
    "## LIME\n",
    "[Lime](https://arxiv.org/abs/1602.04938) stands for local interpretable model-agnostic explanations, meaning that it can be applied to any machine learning model and explains the model's decision for every local sample. By modifying the features of a single sample LIME observes what will happen to the predicted outcome. It then takes the modified dataset to train an interpretable model wich is a good approximation of the local predictions but not global approximation of the model.\n",
    "\n",
    "\n",
    "You will use the Adult dataset with which you are familiar now to explore the explanations of the predictions before and after using the debiasing techniques from the last notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855a6f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets import AdultDataset \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from IPython.display import Markdown, display\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec9c2ae-1a19-4eaa-88bf-80c483e5adeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# protected features\n",
    "protected = 'sex'\n",
    "# privileged class \n",
    "privileged_classes = [['Male']]\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "features_to_keep=['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "# load the dataset \n",
    "ad = AdultDataset(protected_attribute_names=[protected],\n",
    "    privileged_classes=privileged_classes, categorical_features=[],\n",
    "    features_to_keep=features_to_keep)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7d2a47-61d8-4e3e-9dc5-473c2ac0d919",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_df = ad.convert_to_dataframe()[0]\n",
    "ad_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9523365d-1dd1-4b05-8b59-dc3446e4c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train , valid and test set \n",
    "ad_train, ad_test = ad.split([0.7], shuffle = False, seed=0)\n",
    "ad_valid, ad_test = ad_test.split([0.5], shuffle=False, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f83df9-a1af-4dea-bad4-1406f2f2cdb2",
   "metadata": {},
   "source": [
    "#### Train the Block Box Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26c1e9c-1d31-4715-b499-12a4736f32a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load features (For this example we don't scale the data)\n",
    "x_train = ad_train.features\n",
    "y_train = ad_train.labels.ravel()\n",
    "\n",
    "# train the model\n",
    "clf = RandomForestClassifier()   # a black-box classifier\n",
    "clf.fit(x_train, y_train, sample_weight=ad_train.instance_weights)\n",
    "print(f'Accuracy = {clf.score(x_train, y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a18c56a-11d0-41dd-9201-ab2b14049c4c",
   "metadata": {},
   "source": [
    "#### Use Lime to Generate Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f4aa66-418e-4032-94cf-ba4b81465f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from lime import submodular_pick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76aa588-8fd8-448f-87ff-8a2150de7e6b",
   "metadata": {},
   "source": [
    "### Task 3.1.1: Use the Tabular Lime Explainer within the classifier function to explain a local sample. Describe the visualisations of the explanations and interpret them. \n",
    "\n",
    "For the explanation part we only need the classifier function wich takes the classfifier, the train set and the sample number to be explained by Lime. \n",
    "You will need to use the Lime Tabular Explainer which explains classifiers that use tabular data like the Adult dataset. You can familiarize yourself with the modules of Lime [here](https://lime-ml.readthedocs.io/en/latest/index.html). \n",
    "\n",
    "*Hint: The visualiazed data is now scaled but you can still explain their relation (e.g. for age and sex data) or have a look at the original data of that sample. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aedf09-176d-402b-b6a3-b9e498766c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lime_explainer(classifier, x_train, sample_number):\n",
    "    \n",
    "    \"\"\"\n",
    "    Apply the LimeTabularExplainer\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #####################################################\n",
    "    #                   Your code                       #\n",
    "    #####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca6c10c-3803-40f5-8984-14b404c1c19f",
   "metadata": {},
   "source": [
    "### Task 3.1.2: Use the Submodular Pick module within the classifier function to approximate a global explanation. Describe the visualisations of the explanations and interpret them. \n",
    "\n",
    "To get a global view of which features \n",
    "Submodular Pick combines local explanations by averaging the contribution of each \n",
    "\n",
    "You will find an example how to use Submodular pick [here](https://github.com/marcotcr/lime/blob/master/doc/notebooks/Submodular%20Pick%20examples.ipynb).\n",
    "\n",
    "*Hint: Have a look at the parameters and decide which sample size is appropriate for the trade of global approximation and calculation time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1226b334-185c-478e-a146-6b0cfbb46a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submodular_explainer(classifier, x_train, sample_number):\n",
    "    \n",
    "   \n",
    "    \"\"\"\n",
    "    Apply the SubmodularPick module\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #####################################################\n",
    "    #                   Your code                       #\n",
    "    #####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0678173a-d51f-4aa9-9164-4b3d4a740316",
   "metadata": {},
   "source": [
    "#### Get Local Explanations About the Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1356de4-2764-44ef-92c8-401bbd63837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chose a sample from the dataset\n",
    "sample_number = 100\n",
    "lime_explainer(clf, x_train, sample_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6cacf3-2349-40ba-b79e-d7a41fa96cbd",
   "metadata": {},
   "source": [
    "#### Get Global View of Model with Submodular Pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f345578c-ba85-4773-91c8-60ca18ade833",
   "metadata": {},
   "outputs": [],
   "source": [
    "submodular_explainer(clf, x_train, sample_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b9eaf5-dce4-48c2-b7b6-b65d6a5632ac",
   "metadata": {},
   "source": [
    "#### Discuss your Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9305e525-7505-4534-954d-5b9800fe99cd",
   "metadata": {},
   "source": [
    "Your solution for Task 3.1.1:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e80960-7d3f-4ba1-a4cf-8d3f85609a37",
   "metadata": {},
   "source": [
    "Your solution for Task 3.1.2:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2063616e-c6cf-4a77-bdb4-f6a3cb67f926",
   "metadata": {},
   "source": [
    "### Task 3.1.3: Use a preprocessing bias mitigation technique which was introduced in the last notebook and apply both the local and global explanation. Have a look at a sample which belongs to an unprivileged group and compare the explained prediction before and after debiasing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ee776f-3ff3-4c9f-807d-46476816ab4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after debiasing\n",
    "\n",
    "from aif360.algorithms.preprocessing.reweighing import Reweighing\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover\n",
    "\n",
    "# check the documentation and examples of how to use the techniques \n",
    "def preprocessing(train, valid, test, unprivileged_groups, privileged_groups,method=None, repair_level=1,\n",
    "                  k=5, Ax=0.01, Ay=1.0, Az=50.0, print_interval=250, verbose=1, seed=0):\n",
    "    \n",
    "    if method==\"Reweighing\":\n",
    "        RW = Reweighing(unprivileged_groups=unprivileged_groups,privileged_groups=privileged_groups)\n",
    "        RW.fit(train)\n",
    "        return RW.transform(train), valid, test\n",
    "    \n",
    "    elif method==\"DisparateImpactRemover\":\n",
    "        DI = DisparateImpactRemover(repair_level=repair_level)\n",
    "        return DI.fit_transform(train), DI.fit_transform(valid), DI.fit_transform(test)\n",
    "    \n",
    "    else:\n",
    "        print(\"The preprocessing methods is not implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbfb230-1c70-4e95-98e1-080b5886c7cc",
   "metadata": {},
   "source": [
    "#### Retrain Model with Dibiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eca0632-7eec-4a00-9072-29de7aa8ce90",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_train_re, ad_valid_re, ad_test_re = preprocessing(ad_train, ad_valid, ad_test, unprivileged_groups,privileged_groups, method=\"Reweighing\")\n",
    "\n",
    "# load features (For this example we don't scale the data)\n",
    "x_train = ad_train.features\n",
    "y_train = ad_train.labels.ravel()\n",
    "\n",
    "# train the model\n",
    "clf = RandomForestClassifier()   # a black-box classifier\n",
    "clf.fit(x_train, y_train, sample_weight=ad_train.instance_weights)\n",
    "print(f'Accuracy = {clf.score(x_train, y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d559d4-7577-4f42-93c7-20ea80db390b",
   "metadata": {},
   "source": [
    "#### Get Local Explanations About the Debiased Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeb0552-d97a-4c19-8653-2e867357c041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chose a sample from the dataset\n",
    "sample_number = 100\n",
    "lime_explainer(clf, x_train, sample_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4016cc94-73fe-4529-8f4f-d2e9180c968f",
   "metadata": {},
   "source": [
    "#### Get Global View of Model with Submodular Pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b6021f-a633-42d3-8884-fedf5b9e7e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submodular_explainer(clf, x_train, sample_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01618381-b94c-4966-add8-7afb008998be",
   "metadata": {},
   "source": [
    "#### Discuss Your Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee81d67-3f72-4b6a-bf85-874c5b077fed",
   "metadata": {},
   "source": [
    "Your solution for Task 3.1.3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bfb73e",
   "metadata": {},
   "source": [
    "## Image Based Explanations with Innvestigate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad959d30-44da-4d85-9188-230c81fb1055",
   "metadata": {},
   "source": [
    "[Innvestigate](https://github.com/albermax/innvestigate) provides several methods to understand neural networks such as DevConvnet, Deeptaylor and LRP. \n",
    "For this part we will focus on LRP only. \n",
    "LPR stands for Layerwise Relevance Propagation and with LRP the classification decision of a model is backpropagated in order to get information about features which had significant impact on the prediction. For image classification, you will get a heatmap with relevance values which are calculated for every backpropagated layer.\n",
    "LRP is a model specific method and needs different LRP-calculations. \n",
    "There is good explanation [here](https://towardsdatascience.com/indepth-layer-wise-relevance-propagation-340f95deb1ea)\n",
    "\n",
    "For this assignment we well create a grid of visualzations from __three__ XAI methods to help explain why a certain prediction was made using available methods from the [iNNvestigate library](https://github.com/albermax/innvestigate). \n",
    "\n",
    "We will analyze an already trained model for detecting Arched Eyebrows from face images.  The model was trained using a subset of the [CelebA dataset](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc14ce35-e494-43ae-b84f-60b129c55dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necesssary libaries\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import innvestigate\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.applications.imagenet\n",
    "import innvestigate.utils.visualizations as ivis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a778c3f-dbf4-435f-aeed-c483c2d907ee",
   "metadata": {},
   "source": [
    "### Load the Pretrained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbb06c1-d8f2-44d3-9270-f1eb0b533d15",
   "metadata": {},
   "source": [
    "First we need to load our pretrained model.  This model is trained to detect arched eyebrows in images of faces.  The model was trained using the CelebA dataset.\n",
    "\n",
    "NOTE: If you have trouble loading model try running: `pip install h5py==2.10.0 --force-reinstall` at your terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40843292-0ae5-46dd-b10c-855fa0ca8e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "\n",
    "# adding build model function to fix a bug: https://github.com/albermax/innvestigate/issues/177\n",
    "def build_model(num_features):\n",
    "  base = MobileNetV2(input_shape=(224, 224, 3),\n",
    "                     weights=None,\n",
    "                     include_top=False,\n",
    "                     pooling='avg')  # GlobalAveragePooling 2D\n",
    "  \n",
    "  # model top\n",
    "  x = base.output\n",
    "  x = keras.layers.Dense(1536, activation='relu')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.Dropout(0.3)(x)\n",
    "  top = keras.layers.Dense(num_features, activation='softmax')(x)\n",
    "  \n",
    "  return keras.models.Model(inputs=base.input, outputs=top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5983827-4882-424d-8fa7-0b0ece09f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(2)\n",
    "model = load_model('../data/models/weights-FC2-best_model.hdf5')\n",
    "# model.summary()  # uncomment if you're interested in details about the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35461fa1-e0d9-49b2-8c1d-775decf5b819",
   "metadata": {},
   "source": [
    "### Load Example Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e66dd3-a1f6-4b37-84b3-b71ebdc2c416",
   "metadata": {},
   "source": [
    "Next, we will load 10 example images for analysis extracted from the validation partition of the CelebA dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a55c43-73ea-4ef5-bd1d-7d45758a15d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Arched_Eyebrows', 'no_Arched_Eyebrows']\n",
    "\n",
    "# rescaling data between 0 and 1\n",
    "examples_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "example_generator = examples_datagen.flow_from_directory(\n",
    "    directory = '../data/celeba_examples',\n",
    "    target_size = (224, 224),\n",
    "    class_mode = 'categorical',\n",
    "    classes = classes,\n",
    "    batch_size = 1,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b24b94-1750-4dab-aec2-93193cb4cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bonus Task: Try loading your own images, i.e. pictures of yourself or other images that interest you\n",
    "\n",
    "#####################################################\n",
    "#                   Your code                       #\n",
    "#####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8a7e97-66e4-42a3-8fe8-6e567484f935",
   "metadata": {},
   "source": [
    "### Task 3.2.1\n",
    "To get started with iNNvestigate, the final softmax layer of the model must be removed so that innvestigate can work with the model logits.\n",
    "see the [innvestigate.utils module](https://innvestigate.readthedocs.io/en/latest/modules/utils.html#module-innvestigate.utils) for a helper function to remove the final softmax activation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2f4388-6616-4e65-a2c4-298075bf6cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the softmax activation from the model\n",
    "#####################################################\n",
    "#                   Your code                       #\n",
    "#####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc4c2d4-ea9c-4623-8e9f-5a38e3ce92a6",
   "metadata": {},
   "source": [
    "### Task 3.2.2\n",
    "Next, to setup our analyis, we need to define three explainability methods to use, and corresponding parameters and post-processing methods.   For this task, fill in the lists below with 3 XAI methods of your choice, and their corresponding parameters and post-processing methods. You can use the following resources to help. \n",
    "\n",
    "- [iNNvestigate Analysis Tutorial Notebook](https://github.com/albermax/innvestigate/blob/master/examples/notebooks/imagenet_compare_methods.ipynb)\n",
    "- [iNNvestigate API Reference](https://innvestigate.readthedocs.io/en/latest/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d2150a-3b14-4332-aa4c-cb1d756747df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "#                   Your code                       #\n",
    "#####################################################\n",
    "# implement a list of 3 or more innvestigate explainability methods to use\n",
    "methods = []\n",
    "\n",
    "# a list dictionaries for keyword parameters for the corresponding methods\n",
    "method_params = []\n",
    "\n",
    "# a list dictionaries for keyword parameters for the corresponding methods\n",
    "method_preprocessing = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b50dc1-5c91-40aa-a4ab-fc675ffca50e",
   "metadata": {},
   "source": [
    "### Task 3.2.3\n",
    "Now that you have your methods and parameters defined, we will analyze and visualize a set of images using your methods. Fill in the code sections below to perform your analysis and plot the results.\n",
    "\n",
    "Use the above resources for help analysis via iNNvestigate, addtionally review the Matplotlib [imshow](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html) and [subplots](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html) documentation to plot the analysis results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4627d2d5-b617-4cc9-b9ca-ec9896ed99e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = len(example_generator)\n",
    "n_images = 2  # uncomment to try with fewer images for faster results\n",
    "    \n",
    "# For each image loop through all methods to create visualization and save to a list\n",
    "fig, axs = plt.subplots(n_images, len(methods) + 1, figsize=(16, 4.5 * n_images))\n",
    "\n",
    "for y in range(n_images):\n",
    "    image, label = example_generator[y]\n",
    "    \n",
    "    # get prediction\n",
    "    prob = model.predict_on_batch(image)\n",
    "    y_hat_cls = classes[prob.argmax()]\n",
    "    y_cls = classes[label.argmax()]\n",
    "    \n",
    "    #####################################################\n",
    "    #                   Your code                       #\n",
    "    #####################################################\n",
    "    # plot the raw image first and set the label to the \n",
    "    # predicted and ground truth classes.  \n",
    "\n",
    "    \n",
    "    # clean up visualization\n",
    "    axs[y, 0].set_xticks([])\n",
    "    axs[y, 0].set_yticks([])\n",
    "    \n",
    "    for x, (method, params, preprocess) in enumerate(zip(methods, method_params, method_preprocessing), start=1):\n",
    "        \n",
    "        #####################################################\n",
    "        #                   Your code                       #\n",
    "        #####################################################\n",
    "        # create an analyzer for this method\n",
    "        \n",
    "        # analyze image \n",
    "        \n",
    "        # preprocess image for visualization\n",
    "\n",
    "\n",
    "        #####################################################\n",
    "        #                   Your code                       #\n",
    "        #####################################################\n",
    "        # plot image and set a title with the method name\n",
    "        \n",
    "        \n",
    "        # clean up visualization\n",
    "        axs[y, x].set_xticks([])\n",
    "        axs[y, x].set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bace65a-b1a2-409a-8541-950917e721df",
   "metadata": {},
   "source": [
    "### Task 3.2.4\n",
    "Describe the three methods you selected and why you choose those particular methods.  Finally, describe your findings and interesting insights from implementing the methods for XAI, including how you think these methods enable (or not) interpretable machine learning.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681321ae-ea81-4243-9d9a-ed1ea695e169",
   "metadata": {},
   "source": [
    "Your findings here..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
